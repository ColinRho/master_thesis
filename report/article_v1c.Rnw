%%% thesis
\documentclass[12pt]{article}
\usepackage[fleqn]{amsmath}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{natbib}
\usepackage{graphicx}
  \graphicspath{{../plot/}}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{color}
\usepackage{titlesec}
\usepackage{gensymb}
\usepackage{soul}
\usepackage[utf8]{inputenc}
\usepackage{caption}

\newcommand{\cred}{ \color{red}}
\newcommand{\cgreen}{\color{green}}
\newcommand{\cblue}{\color{blue}}
\newcommand{\cmag}{\color{magenta}}
\newcommand{\bn}{\begin{enumerate}}
\newcommand{\en}{\end{enumerate}}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{eqnarray}}
\newcommand{\ee}{\end{eqnarray}}
\newcommand{\by}{\begin{eqnarray*}}
\newcommand{\ey}{\end{eqnarray*}}
\renewcommand{\labelenumi}{(\alph{enumi}) }
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
%
\usepackage[margin=2.2cm, includehead]{geometry}% see geometry.pdf on how to lay out the page. There's lots.
\geometry{letterpaper} % or letter or a5paper or ... etc
% \geometry{landscape} % rotated page geometry
%\bibpunct{(}{)}{;}{a}{,}{,}
%\setlength{\textwidth}{16cm}
%\setlength{\textheight}{21cm}

\newcounter{parnum}
\newcommand{\N}{%
  \noindent\refstepcounter{parnum}%
   \makebox[\parindent][l]{\textbf{[\arabic{parnum}]}}\quad  }
% Use a generous paragraph indent so numbers can be fit inside the
% indentation space.
\setlength{\parindent}{1.5em}

% See the ``Article customise'' template for come common customisations

<<setup, cache=FALSE, echo=FALSE>>=
library(knitr)
library(xtable)
opts_knit$set(root.dir = normalizePath('../'))
opts_chunk$set(cache = TRUE, autodep = TRUE, echo = FALSE, results='asis')
@

<<loading, cache=TRUE, echo=FALSE>>=
source("source/functions.R")
load("data/precedent.RData")
@

\usepackage[nomarkers]{endfloat}


\begin{document}

\title{Modelling the entire range of daily precipitation using mixture distributions}
\author{Hyunwoo Rho}
\date{}

\maketitle

\titlelabel{\thetitle.\quad}


%%%
%========================
\section{Introduction}
%========================

Measuring and predicting the precipitation are considered to be of great importance in many applications, including  agriculture, forest management and hydrology. Common models of  the precipitation are stochastic, in that they describe the phenomenon of rainfalls through some static or dynamic statistical models with specific distributions, with a suitable time interval as a base period of modelling. The choice of the time interval can be arbitrary in theory, but taking a daily basis is most natural and popular in the literature; see, for example, \cite{richardson1981stochastic}.\\

Many of previous studies tried to model daily rainfall data through parametric approaches, for example, \cite{ison1971wet, mielke1973three, richardson1981stochastic, stern1984model}. Non-parameteric approaches have also been proposed by, e.g., \cite{sharma1999nonparametric, harrold2003nonparametric}. Though each approach has pros and cons, parametric models are generally advantageous in that they can model rainfall datasets with only a few parameters and can be easily extrapolated towards extreme area where rainfall observations are relatively rare in frequency. Simple  parametric models found in the literature include exponential, gamma and some transformed normal distributions. However, these simple models often fail to capture important characteristics of the rainfall datasets which are typically skewed, over-dispersed, relatively heavy-tailed, and sometimes bell-shaped. As an alternative approach to improve the calibration, mixtures of two parametric distributions have been suggested in the literature. \\
 
Being natural extensions of those simple stochastic models, the class of mixture distributions is more flexible with more parameters, and thus can address unique shape characteristics of the rainfall datasets. Successful applications of the mixture distributions towards the precipitation datasets can be abundantly found in the literature. For example, {\cblue \cite{woolhiser1982stochastic} adopted mixed exponential distribution and \cite{yoo2005rainfall} exploited mixed gamma distribution. From recent study of \cite{vrac2007stochastic, hundecha2009modeling}, dynamic mixture of gamma and generalzied Pareto distribution was considered to give more focus on extreme cases.} {\cred references here.}\\
\vspace{2cm}

Related to this, along some studies in hydrology community, the evidence of heavy-tailed phenomenon on the distribution of high precipitation amount has recently gained strong support from researchers; see, e.g.,  \cite{koutsoyiannis2004statistics}. The underlying idea of the heavy tail essentially says that the extreme precipitation amounts over some high threshold value tend to have different distributional behaviours and, accordingly, can be modelled using a separate statistical distribution. In particular, the distribution for the tail is modelled by the generalized Pareto distiribution (GPD) justified by the standard result of extreme value theory (EVT). To this extent various methods were investigated and explored in the literature, focusing on the tail behavior of daily precipitation described by some power (or polynomial) survival function; see, for instance, \cite{furrer2008improving, li2012simulation, papalexiou2012entropy, papalexiou2013extreme}. Most notably, \cite{li2012simulation} presented a hybrid distribution to model the full spectrum of daily precipitation under the EVT framework where the body and tail parts of the dataset are modelled by an exponential and the GPD, respectively. However, there seems no universal agreement on how heavy the precipitation amounts are. \st{For example}, \cite{wilson2005fundamental} \st{pointed out that extreme daily precipitations of some areas can be adequately modelled by an exponential tails, which is shorter than a power tail.} {\cblue For example, \cite{booij2002extreme} tried to model extreme daily precipitations with Gumbel distribution and exponential distribution, which have exponential tail, shorter than a power tail.} This implicitly suggests that there is no need of separate modelling for the tail as long as the candidate distributions have exponentially decaying tails. {\cblue  Also \cite{park2011changes} compared several GEV distribution based model and revealed both power tail model and exponential tail model could be adopted to explain extreme rainfalls. } {\cred more similar references needed.} Thus it remains controversial that whether the precipitation extremes follow a power-tail or an exponential-tail, and it is reasonable to say that, depending on the area under consideration, an exponential-type distribution or its mixture may serve as a good candidate to describe the rainfall datasets' body as well as tail. \\

In this paper, we are interested in modelling the entire range of typical precipitation datasets. For this, we propose the phase-type distribution (PHD) as an alternative mixture distribution to model the precipitation. The PHD is a class of mixture distributions that contains many well-known distributions, such as an exponential and Erlang mixture,  as members. Though this distribution class has been used in reliability and insurance contexts, its applications towards the precipitation seems not found in the current literature. For the purpose of the present article, we closely follow the work of \cite{li2012simulation} where Texas rainfall datasets are analyzed using various single and hybrid models, both with and without the EVT framework. In particular, we use the identical datasets and model them with the PHD and compare with other existing parametric models. Later we also use the global precipitation datasets used in, e.g.,  \cite{papalexiou2012entropy, papalexiou2013extreme} for further analysis as the global datasets exhibit somewhat different characteristics.
For these datasets we carry out extensive fitting exercises and standard model validations and show that the PHD is a flexible, competitive and well-rounded alternative stochastic model in describing the whole range of precipitation datasets of different shapes. \\

The present article is organized as follows. In Section 2. {\cred I will revise below later.}
we compare various existing parametric models in the literature and further introduce a particular type of mixture distribution called phase-type distribution. Through this model we tried to fit the whole range of continuous daily precipitation. Moreover, model evaluation was done with concentration on the tail part as well as the entire data. 


%%%
%========================
\section{Data Sets}
%========================
Let us first describe the datasets to be used throughout the present article. The main data set analysed is United States Historical Climatology Network (USHCN) Daily data set. Raw data set contains daily record of precipitation, snowfall, snow depth, maximum temperature, minumum temperature, and information about flag. Among 48 files of each {\cblue c}ontiguous states, we selected Texas which has {\cred 49 stations (correct?)} {\cblue yes}, following \cite{li2012simulation}. Further, the same data selection criteria were adopted so that all non-zero precipitation values during 1940 and 2009 are included, without taking care of missings. \\

The second set of data, which will be analyzed separately later in this article, is a global precipitation dataset from 
 Daily Global Historical Climatology Network (GHCN-DAILY), which has also been widely used in precipitation analyses in the literature. This dataset includes about 100,000 stations and contains USHCN as its subset. We filtered stations according to \cite{papalexiou2013extreme}, that is, we only included stations that have: (a) record length of over 50 years, (b) percentage of missing values less than 20\%, data assigned with suspicious "quality flags" less than 0.1\%. The screen values of quality flags are two, one with "G"(failed gap check), and another with "X"(failed bound check). For more information about this dataset, see \cite{menne2012overview}. 
After data cleansing, we obtained the records of 19,328 stations from GHCN, which are almost identical to those used in  \cite{papalexiou2012entropy} and \cite{papalexiou2013extreme}. Although USHCN data is a near subset of GHCN data, we analyze them  individually as they have distinct characteristics.

<<tx summary>>=
summary_stations <- sapply(1:49, function(x) {
  
  y = by_station(ID = x) 
  summary(y)  
})

mat <- cbind.data.frame(ID = unique(tidy.ushcn.tx[["COOP_ID"]]),
  Label = paste("ID", 1:49, sep = ""),
  t(summary_stations))

xtab <- xtable(mat, caption = "Summary of USHCN Texas data set")
print(xtab, booktabs = TRUE, size = "\\tiny")
@

%%%
%========================
\section{Existing models}
%========================


<<sample histogram, fig.cap = "Sample histrogram : ID2">>=
y = by_station(2)
hist(y, probability = TRUE, breaks = 60, main = "", xlab = "Precipitation (mm)")
summ <- summary(y) ; nm <- names(summ)
legend('topright', legend = paste(nm, summ, sep = " "), title = paste("ID", 2,
  sep = ""), box.col = "white")
@

%%%
%-------------------------------------
	\subsection{Single component models}
%-------------------------------------

<<single_models, fig.cap = "QQ plots of ID2 modelled by single component models; Exponential, gamma, and kappa", warning=FALSE>>=
layout(matrix(1:3, ncol=3))
generalQQplot(y, model = "exp gamma kappa")
@


Fundamental characteristrics of daily precipitation data are described as non-negative, continuous except at the spike on zero, and right-skewed. Assuming we only focus on the continuous part of the data, common candidate statistical models include exponential distribution by, e.g., \cite{todorovic1975stochastic}, gamma distribution by \cite{ison1971wet, wilks1999interannual, schoof2010development}, and kappa  distribution by \cite{mielke1973three}, to name a few. Let $X$ denote the non-zero daily precipitation amount, then each model's probabilty density function is given by:

\begin{equation}
  \label{eq:exponential.pdf} 
Exponential: \quad   f(x ; \lambda) = \frac{1} {\lambda} e^{-x / \lambda}, \quad x \geq 0, \quad \lambda > 0,
\end{equation}


\begin{equation}
  \label{eq:gamma.pdf} 
Gamma: \quad   f(x ; \alpha, \beta) = \frac {1} {\beta^\alpha \Gamma(\alpha)} x^{\alpha - 1} e^{-x/\beta} , \quad x \geq 0, \quad \alpha, \beta > 0,
\end{equation}


\begin{equation}
  \label{eq:kappa.pdf} 
Kappa: \quad   f(x ; \alpha, \beta, \theta) = \frac {\alpha \theta} {\beta} (\frac {x} {\beta})^{\theta - 1} [\alpha + (\frac {x} {\beta})^{\alpha \theta}]^{-\frac {\alpha + 1} {\alpha}}, \quad x > 0, \quad \alpha, \beta, \theta > 0,
\end{equation}

Clearly, these models are ordered in that they become increasingly more flexible with more parameters. Other distributions can also be found, such as, skewed-normal \citep{wan2005stochastic}, truncated power of normal distribution \citep{bardossy1992space}, and genralized Pareto distribution (GPD) provided that only the tail of dataset is modelled. The list of possible single component models can surely be much longer, but we restrict ourselves to these three models to avoid crowded model comparison. However, as evidenced in previous studies, it is now much agreed that single component models are generally inadequate to describe the whole range of daily precipitaion datasets. To illustrate this, we present the fitted result of these three models for Texas Station ID 2 (ID 2, in short) data in Figure \ref{fig:single_models}. From the figure, we see that the exponential and gamma models underestimate the tail, and the kappa model overestimates it. With other stations, this tendency is unchanged, and the fits are generally extremely poor. 


%%%
%-------------------------------------
	\subsection{Multi component models} 
%-------------------------------------

Further improvement in fitting can be achieved by inserting additional distribution to single component models. In this regard, mixture type distributions were suggested in the literature, including a mixed exponential distribution \citep{woolhiser1982stochastic,wilks1999interannual} and dynamic mixture of gamma and GPD \citep{vrac2007stochastic, hundecha2009modeling}. Alternatively, hybrid models could be considered, os which the density is created by stitching two densities at a particular threshold. A hybrid distribution is also known as a composite distribution in the statistical literature.  In recent studies, \cite{furrer2008improving} suggested  a hybrid distribution of gamma and generalized Pareto distribution (GGP in short), and \cite{li2012simulation} proposed a hybrid of exponential and generalized Pareto distribution (EGP). Both of these models take generalized Pareto distribution (GPD) as the upper tail distribution to reflect heavy tail behaviuor of precipitation extremes \citep{koutsoyiannis2004statistics}. Just like single component models, one can create infinitely many different mixture or hybrid models, and it is not feasible to consider all possible candidates. An extensive comparative study of \cite{li2012simulation} \st{shows that the performance of hybrid models defeat the one of mixture models in general} {\cblue found out that the performance of hybrid models surpasses the mixture models considered.} {\cred Please revise this sentence. it is too vague to me. make it more detailed.}. Hence, we mainly cover the hybrid models to be compared rather than other mixture distributions. 


\begin{align}
  \label{eq:gamma_gp_hybrid.pdf}
  f(x ; \alpha, \beta, \xi, \sigma, \theta) &= f_{gam}(x ; \alpha, \beta) I(x \leq \theta) + [1-F_{gam}(\theta ; \alpha, \beta)] f_{GP}(x ; \xi, \sigma, \theta) I(x > \theta) \nonumber \\
    & x \geq 0, \quad \alpha, \beta, \xi, \theta > 0 
\end{align}


Where $f_{gam}$ and $F_{gam}$ are probabilty density function and cumulative distribution fucntion of gamma respectively. To make it continuous at the threshold $\theta$, , a constraint $f(\theta-) = f(\theta+)$ is needed, which yields that the scale parameter $\sigma$ of generalized Pareto distribution is expressed as the reciprocal of the gamma hazard funciton, 


\begin{equation}
  \label{eq:GGP_sigma}
  \sigma = \frac {1 - F_{gam}(\theta ; \alpha, \beta)} {f_{gam}(\theta ; \alpha, \beta)}
\end{equation}


As a result, its parameter set reduces to $\{\alpha, \beta, \xi, \theta\}$. Even though the model complexity have been descreased, still the threshold selection problem remains, which doesn't have any guaranteed method and entails cumbersome trial-and-error task. Hybrid of exponenetial and generalized Pareto distribution \cite{li2012simulation} has an advantage on such huddle by passing away it via analytical derivation of threshold.


\begin{align}
  \label{eq:exponential_gp_hybrid.pdf}
  f(x ; \lambda, \xi, \sigma, \theta) &= \frac {1} {1 + F_{exp}(\theta ; \lambda)} [f_{exp}(x ; \lambda) I(x \leq \theta) + f_{GP}(x ;  \xi, \sigma, \theta) I(x > \theta)] \nonumber \\ 
   & x \geq 0, \quad \lambda, \xi, \sigma, \theta > 0 
\end{align}


With same constraint above to get a continuity, $f(\theta-) = f(\theta+)$, the number of parameters can be reduced again. 


\begin{equation}
  \label{theta_expression}
  \theta = -\lambda \ln{\frac {\lambda} {\sigma}}
\end{equation}


Then the parameter set of EGP model becomes $\{\lambda, \xi, \sigma\}$. By sacrificing model flexibity with taking exponential rather than gamma on its body part, it obtains a primary advantage circumventing the threshold selection problem.


%%%
%========================
\section{Phase-type distribution class}
%========================



%%%
%========================
\section{Analysis}
%========================


%% estimation method
Model parameters are estimated via maximum likelihood method. Especially for fitting Phase-type distribution, a kind of EM algorithm proposed by \cite{asmussen1996fitting}. 

For GGP model, estimation procedure of by \cite{furrer2008improving} was applied. Also its performance is affected by the choice of threshold value. Too large threshold would estimate its tail short by taking large emphasis on gamma distribution. Otherwise too small threshold set large emphasis on genralized Pareto and estimate its tail heavy. In \cite{li2012simulation}, this model indicated its best performace with threshold $\theta = 3.99$, that is around .Thus we set threshold value used in GGP model moderately as 55\% quantile of each sample and avoid cumbersome optimal threshold selection procedure.


    %%%
    %------------------------------------- %>% 
      \subsection{Model comparison}
    %-------------------------------------

As shown in Figure \ref{fig:single_models}, single component models are not enough to sufficiently depict the entire range of daily precipitation amount. Hence we exclude those models at in depth comparison analysis among models and mainly cover the multi component models in this section; GGP, EGP, and PH model. 


\begin{figure}
  \centering
  \includegraphics{QQplot_multicomp.pdf}
  \caption{QQ plots of 3 different stations modelled by GGP distribution(left), EGP distribution(middle), and the PH distribution(right)}
  \label{fig:multicomp}
\end{figure}


Figure \ref{fig:multicomp} presents fitting result of three models on three different stations of USHCN Texas data set. All the models show good performances in general especially in the body part of the data. Differences stand out at the tail part. Throughout three of stations, EGP model estimates its tail thickness heavier than sample data points, because points at tail part of QQ plot are marked on the lower side of 45 \degree line. For ID44, EGP gets poor result by estimating its tail thickness too large. On the other hand, GGP and PH model results exhibit similar pattern, even performance of GGP highly depends on choosing the threshold value. 

Visual model evaluation methods like QQ plot have advantage on concise and dramatical comparison bewteen distinct models. With Figure \ref{fig:multicomp}, however, accurate comparison is problematic. Therefore numerical measurement is needed for precise research. Akaike information criteria(AIC) \cite{akaike1974new} is well known and most widely used model selection method. It has an advantage of reflecting model complexity by giving penalty on the number of parameters. AIC surpassed visual comparison methods especially in this case, since three models above have different number of parameters, which are 4 of GGP, 3 of EGP, 5 of PH distribution.


<<goodness of fit>>=
tab <- fread("results/infotable.csv")
xtab <- xtable(tab, caption = "Infomation Table", label = "tab:aic")
print(xtab, booktabs = TRUE, size = "\\tiny", include.rownames = FALSE)
@


AIC values for each stations and each models are presented in Table \ref{tab:aic}. With AIC values, the smallest is the best. Especially for ID2, ID11 and ID44 from Figure \ref{fig:multicomp}, PH distribution is chosen as the best model according to AIC values. Even with all 49 stations of USHCN Texas, PH distribution is selected as the best model of 41 stations among them, but GGP distribution couldn't at least once. Despite we can enhance the fitting performance of GGP distribution by finding the optimal threshold value, still such cumbersome procedure is not desirable. 

%% compare 2-phase PH model and EGP model 
Even we can try to compare more limited version of PH distribution and EGP distribution. As we restrict the number of phases to two, also with Coxian assumption, the number of parameters of PH model becomes three, same with EGP model. 
%% after analysis

<<best aic>>=
aic.tab <- aic.tab <- tab %>% select(., contains("AIC"))
aic.best <- apply(aic.tab, 1, which.min) 

aic.best[aic.best == 1] <- "GGP"
aic.best[aic.best == 2] <- "EGP"
aic.best[aic.best == 3] <- "PH"
  
print(xtable(table(aic.best),
  caption = "Number of selection as best model by AIC", label = "tab:bestaic"),
  booktabs = TRUE, include.colnames = FALSE)
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    %%%
    %-------------------------------------
      \subsection{Observation on extreme values}
    %-------------------------------------


As mentioned earlier, there is a controversy on the tail behavior of daily precipitation data. There are two well known approaches and corresponding statistical methods to investigate the extreme values; block maxima(BM) with generalized extreme value distribution(GEV) and peaks over threshold(POT) with generalized Pareto distribution(GPD). Both of distributions have shape parameter $\xi$, which determines tail behavior of data. GHCN data set, which contains about 20000 stations around the world, is used to figure out thet general tail characteristics of daily precipitation data. Also, to make consistency with foregoing models; GGP and EGP, we take POT-GPD approach on examining tail data. 

Then it becomes contentious issue that how to define the extreme values. Some commonly used criteria are above 95\% or 98\%. But we adopt a conventional way in hydrology \cite{cunnane1973particular}, that is to make the number of values above the threshold equal to the number of years of observation record. 


\begin{figure}
  \centering
  \includegraphics{dist_xi.pdf}
  \caption{Empirical distribution of $\hat{\xi}$ and fitted normal curve. $\hat{\xi}$ is estimated from each of 19328 stations of GHCN data set.}
  \label{fig:empirical_xi}
\end{figure}


In the extreme value theory(EVT), the tail thickness of data is determined by the shape parameter $\xi$. If it has negative $\xi$, it has upper bound, or if $\xi$ is zero, it has a exponential tail, or if it has positive $\xi$, it has a polynomial tail which is much heavier than exponential. Figure \ref{fig:empirical_xi} is the empirical distribution of $\hat{\xi}$ and it seems symmetric bell-shape distribution like normal distribution. Fitted line is a normal density curve having sample mean and sample standard deviation as its parameter, which are 0.0896 and 0.1814 respectively. About 29\% of estimates are obtained in negative value. One can say that this estimating results support that the shape parameter $\xi$ has postive value in general. However, in the point of view of hypothesis testing, it is hard to say that $\xi$ is not zero. 

Phase-type distribution is a mixture of several gamma distributions and one exponential distribution. Thus its tail behavior follows exponential tail theoretically. The fundamental characteristic of extreme value of daily precipitation data is still arguable, like comparable fitting results of Figure \ref{fig:multicomp}. More precise research on extreme values is needed to figure out that which kind of tail assumption is more appropriate with precipitaion data. 


<<qm.list, cache=TRUE>>=
ids = c(2, 5, 9, 11, 15, 24, 31, 44)
quantmatch <- function(q = 0.9, ids = c(2, 5, 9, 11, 15, 24, 31, 44)) {

  mat <- t(sapply(ids, function(x) {
    
    qmat <- fread(paste("results/qmat.", x, ".csv", sep = ""))
    
    qmat %>% filter(., y >= quantile(y, q)) %>% select(., contains(".sq")) %>%
      colSums() / nrow(qmat) 
    
  })) %>% data.frame()
  
  mat
}

qmlist <- sapply(c(0.9, 0.95, 0.98), quantmatch) %>% do.call("cbind", .)
qmlist <- data.frame(paste("ID", ids, sep = ""), qmlist)
colnames(qmlist) <- c("ID", rep(c("GGP", "EGP", "PH"), 3))

cmnd <- c('& $\\eta$ = 0.9 & & & $\\eta$ = 0.95 & & & $\\eta$ = 0.98 \\\\\n\\toprule\n' )
xtab <-xtable(qmlist, label = "tab:qmatch",
  caption = "Mean of square qunatile difference with each value of $\\eta$ equals to 0.9, 
  0.95, 0.98") 

print(xtab, 
  include.rownames = FALSE,
  add.to.row = list(pos=list(-1),
    command = cmnd),
  booktabs = TRUE)
@


Some methods testing goodess of fit like Kolmogorov-Smirnov(KS), Cramer von Mises(CvM), and Anderson-Darling(AD) statistic include a term of difference between empirical distribution function $F_n$ and model distribution fuction $\hat{F}$. Similarly, we exploit some statistic $Q(\eta)$ based on quantile function $q$, which is simply the inverse of distribution function $F$.


\begin{equation} 
  \label{eq:quantile_match}
  Q(\eta) &= \frac {\sum_{i:q_i \geq \eta}^n (q_i - \hat{q}_i)^2} {n}, \quad \eta \in [0, 1] \\ 
\end{equation}
$n$ : sample record length, $q_i$ : $i^{th}$ sample quantile, $\hat{q}_i$ : $i^{th}$ theoretical quantile


This approach is really straightforward way to evaluate each model with given sample. As we take $\eta$ of $min(x_i)$, $Q(\eta)$ represents model performance for the entire range of data. Then, by increasing a value of $\eta$ close to $1$, $Q(\eta)$ measures performance of model on extreme part of data. Tail performances of each models, GGP, EGP, and PH are evaluated by $Q(\eta)$ with commonly used tail indicating probabilty 0.9, 0.95 and 0.98 on Table \ref{tab:qmatch}. 

Because $Q(\eta)$ is sort of mean squared error, the smaller is the better. Among 8 stations on table, except station ID2 and ID44, PH model defeats other models. Even with ID2 and ID44, PH model takes second placeds at least. We can find some tendency that the margin between PH model and others getting smaller as $\eta$ increases. Such phenomena occur far more drastically with low value of $\eta$. This means even we would not realize the difference of fitting performances among each models in visual comparison like Figure \ref{fig:multicomp}, PH distribution can model body part more accurately. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


    %%%
    %-------------------------------------
      \subsection{Distinct instance}
    %-------------------------------------


In the research of \cite{papalexiou2012entropy}, wordwide GHCN data set was analyzed to figure out its shape of empirical distribution and tail behavior. To capture the shape characteristics of each sample, L-moments ratio was used. A typical L-moments ratio diagram is made with L-skewness versus L-kurtosis, but with precipitation data, but we prefer L-varaiation versus L-skewness as \cite{papalexiou2012entropy} done before. As a result two distinct shapes were observed called J-shaped and bell-shape distriution. A typical type of parametric model having J-shape distribution is exponential model. The level of J-shaped feature could be judged visually by high peak and steepness around zero; a steeper, a more J-shaped. This kind of empirical distribution is usual case of precipitation data. But bell-shape distributions is well known with noraml distribution. Though, in this case we have non-negative and right-skewed random variable, thus we say it has bell-shaped distribution if it has such shape on the body part of the distribution, like gamma distribtion with its shape parameter greater than one. 


\begin{figure}
  \centering
  \includegraphics[width=15cm]{lmrd.pdf}
  \caption{L-variation vs. L-skewness plot}
  \label{fig:lmrd}
\end{figure}


<<bell J texas, fig.cap="Histograms of bell-shape(right), J-shape(middle), and one of USHCN Texas(right) data">>=
Mmat %>% filter(., t_2 >= 0.7 & t_3 >= 0.7) -> JShape
Mmat %>% filter(., t_2 <= 0.43 & t_3 <= 0.43) -> BellShape

layout(matrix(1:3, ncol = 3))
hist(get.station.data(BellShape$Id[1]), probability = TRUE, breaks = 60, main = "", xlab = "")
hist(get.station.data(JShape$Id[3]), probability = TRUE, breaks = 60, main = "", xlab = "")
hist(by_station(3), probability = TRUE, breaks = 60, main = "", xlab = "")
@


L-moments ratio diagram made with GHCN data set, Figure \ref{fig:lmrd}, shows rough positive linear relationship between L-variation and L-skewness. The larger value of L-variation and L-skewness, the more J-shaped. Square red dots plotted on Figure \ref{fig:lmrd} represent 49 stations of USCHN-Texas data set. Those sample stations are more likely to be J-shaped rather than bell-shaped according to their position on L-moments ratio diagram. Both GGP and EGP model are only simulated only with such J-shaped sample data, and did not consider other extreme cases of bell-shaped data. 

Especially for EGP model, it has fundamental defect on modelling bell-shaped data since it takes exponential distribution as its body part model. Accordingly, estimates couldn't be obtained with original parameter space in \ref{eq:exponential_gp_hybrid.pdf}, but estimation succeeded with negative value of $\xi$. Negative value of shape parameter is still embarrassing result since it infers bounded tail as reported by extreme value theory. 


\begin{figure}
  \centering
  \includegraphics{QQplot_bell.pdf}
  \caption{QQ plots for bell-shaped sample station modelled by GGP, EGP, and PH model}
  \label{fig:qq_bell}
\end{figure}


In Figure \ref{fig:qq_bell}, unlike USHCN Texas samples, body parts of GGP and EGP QQ plot are under the 45 \degree line. PH model, however, still performs well with bell-shaped sample on both body and tail part. Such strength comes from flexible mixing procedure of PH distribution. This result means PH model can be the generally accepted model for daily precipitation data including both J-shaped and bell-shaped distribution. 



    %%%
    %-------------------------------------
      \subsection{Model expansion on dry days}
    %-------------------------------------


Remarkably, phase-type distribution even can model data including zeros. From {\cblue density function of phase-type distribution should be here}, the originial domian of phase-type distribution only permits strictly positive values. Recall that the concept of phase-type distribution measures abosorption time going through Markov process with initial probability vector $\alpha$ and transition matrix $T$ and constrant for $\alpha$ to satisfy $\alpha \boldsymbol{1} = 1$. By simply adding extra parameter $p$ indicating non-zero probabilty to probabilty vector $\alpha$, phase-type distribution can be a comprehensive stochastic rainfall generator. Estimation process for phase-type distribution is same as before, only with strictly postive values, then just to multiplty non-zero probability to $\alpha$, but Markov trasition matrix $T$ does not change.


\begin{equation}
  \alpha_p = \alpha (1 - \frac{\sum_{i = 1}^n I(x_i = 0)} {n}) \\
  \label{eq:alpha_p}
\end{equation}


Since we have used a special case of PH distiribution called Coxian distribution {\cblue referecing Coxian stuff here}, $T$ is only parameter to be estimated. To cover zero values, $\alpha_p$ is estimated with number of zero records in sample but $T$ is still estimated only with non-zero records. For instance, in Fort Stockton, represented by ID24 of USHCN Texas data set, there were 20422 dry days of 23443 total days recorded from 1940 to 2009. Then we can say that a rainfall probabilty of Fort Stockton is 12.88\% in average, and modify the probability vector $\alpha$ into $\alpha_{p}$.


\begin{equation}
  \alpha = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix},
  \quad
  \hat{\alpha}_p = \begin{pmatrix} 0.1288 \\ 0 \\ 0 \end{pmatrix},
  \quad
  \hat{T} = 
    \begin{pmatrix}
      -0.5589 & 0.2713 & 0 \\
      0 & -0.1197 & 0.0161 \\
      0 & 0 & - 0.0505
    \end{pmatrix} 
  \label{eq:estmates_ID24}
\end{equation}




%%%
%========================
\section{Conclusion}
%========================








%following selects the referencing style
\bibliographystyle{natbib}
%following selects the reference bib file
\bibliography{myrefs}

\end{document}